"""
Script.

Compare how quickly different Wang Landau simulations converge to their final F value.

Input data is generated by running      ./get_data.sh wl    in an appropriate directory.

Argument variables provide the input files.
Multiple simulations with the same simID (set in params.py) will be averaged over.

Run as e.g.     python compare_wl.py file1.txt file2.txt
"""

import numpy as np
import matplotlib.pyplot as plt
from sys import argv, exit

# Import information on input files, simulation data from sim_info.py (make sure it's correct!)
import sim_info

# Generic plot parameters
plt.rc('text', usetex=True)
font = {'family' : 'serif',
        'size' : 14}
plt.rc('font', **font)
colors = ('b', 'g', 'm', 'c')

# Create plot
fig, ax = plt.subplots()
ax.tick_params(direction='in', top=True, right=True)
ax.set_xlabel(sim_info.axis_label)
ax.set_title("Comparison of Wang Landau simulations")
ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))

# Sort out ticks and labels on categoric axis
Nsid = len(sim_info.sim_labels)
ax.set_xticks(range(Nsid))
ax.set_xticklabels(sim_info.sim_labels)

# Input file names given as arguments
input_files = argv[1:]
Nfiles = len(input_files)

# Quick check
if Nfiles == 0:
    print "Error: Please provide one or more input files as arguments"
    exit(1)


# Iterate over input files
for ifile in range(Nfiles):

    # Initialise lists
    simID = []
    F_final = []
    Ns = []
    sweeps_alls = []

    print "Reading data from file: ", input_files[ifile]

    # Open file and read data
    # (Not using np.loadtxt since number of sweeps/cols can vary)
    with open(input_files[ifile]) as f:
        for line in f:
            
            # Convert line from string to list of floats
            line_float = map(float, line.split())

            # Append single numbers to lists
            simID.append(line_float[0])
            F_final.append(line_float[1])
            Ns.append(line_float[2])

            # Sort out sweeps using numpy arrays and append to lists
            sweeps_array = np.array(line_float[3:])
            sweeps_alls.append(sweeps_array)

    # Check that all simulations have converged to the same F
    F_final = np.array(F_final)
    if np.min(F_final) != np.max(F_final):
        print "Error: simulations have converged to different F values"
        exit(1)
    F = F_final[0]


    # ------------------------------------------ #
    #  Average over simulations with same simID  #
    # ------------------------------------------ #
    # Initialise lists to hold averages over repeats
    sweeps_rmean_alls = []
    sweeps_rmean_smean = []
    sweeps_rmean_serr = []

    unique_Ns = []
    N_repeats = []
    unique_simID = np.sort(np.array(list(set(simID)), dtype=int)) # low->high simID
    simID = np.array(simID, dtype=int) # convert to int for usid == sid expression
    
    # Iterate over unique simID's
    for usid in unique_simID:

        # List of row numbers with this value of simID (reps to be averaged over)
        index_list = [i for i, sid in enumerate(simID) if usid == sid]
        i0 = index_list[0]

        # Keep track of the number of sims we're averaging over
        N_repeats.append(len(index_list))
        print "Averaging over %d simulations for simID: %d (%s)" \
                %(len(index_list), usid, sim_info.sim_labels[usid])

        # Assume repeats have same Ns - pretty safe to assume
        unique_Ns.append(Ns[i0])
    
        # Pull out the sweeps to be averaged over
        data_to_average = [] # store values for each repeat, subdomain
        for i in index_list:
            data_to_average.append(sweeps_alls[i])
    
        # Data in form (rows, cols) = (repeats, subdoms)
        data_to_average = np.array(data_to_average)

        # Average over repeats, subdoms still separate (useful to see trends)
        sweeps_rmean_alls.append( np.mean(data_to_average, axis=0) )
    
        # Average over repeats AND subdoms
        data_to_average = data_to_average.flatten()
        sweeps_rmean_smean.append( np.mean(data_to_average) )
        sweeps_rmean_serr.append( np.std(data_to_average) / np.sqrt(len(data_to_average)) )

    
    # End loop over unique values of simID


    # Convert data to arrays / ints for manipulation / indexing
    sweeps_rmean_smean = np.array(sweeps_rmean_smean)
    sweeps_rmean_serr = np.array(sweeps_rmean_serr)
    Ns = np.array(unique_Ns, dtype=int)

    # ------------- #
    #  Add to plot  #
    # ------------- #
    # Input file is a key to access dictionary, value describes the simulation
    label = sim_info.file_labels[ input_files[ifile] ]
    
    # X axis for bar plot, with offsets when multiple input files
    if Nfiles > 1:
        fake_xticks = np.arange(Nsid) + np.linspace(-0.2, 0.2, Nfiles)[ifile]
        width = 0.8/Nfiles
    else:
        fake_xticks = np.arange(Nsid)
        width = 0.8
    
    # Plot mean and standard error
    ax.bar(fake_xticks[unique_simID], sweeps_rmean_smean, width=width, color=colors[ifile], label=label)
    ax.errorbar(fake_xticks[unique_simID], sweeps_rmean_smean, yerr=sweeps_rmean_serr, fmt='ko')

    # Plot a little line to show any trends in subdomain convergence
    xwidth = width
    for i in range(len(unique_simID)):
        x = np.linspace(-xwidth, xwidth, Ns[i]) + fake_xticks[i]
        ax.plot(x, sweeps_rmean_alls[i], 'r-')


# End loop over input files


ax.set_ylabel("Sweeps to reach $F-1=$%.1e" %(F-1))
ax.legend()
plt.tight_layout()
plt.show()

