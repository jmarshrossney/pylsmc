"""
Script.

Compare how quickly different 'dF' (multicanonical/transition matrix) simulations converge on
a result for the free energy difference between the two lattices.

Input data is generated by running      ./get_data.sh dF    in an appropriate directory.

Note that multiple simulations with the same simID (set in params.py) will be averaged over,
rather than compared.

Argument variables give the type of comparison to make:
No argument variable: Compares the values and uncertainties on dF for different simulations.
                      They must have run for the same number of sweeps!
                      Input file = "dF_data.txt"

argv[1] == 'std': Compare standard deviation as a function of sweeps for different simulations.
                  Input file = "stdev_series.txt"

argv[1] == 'psi': Compute the speedup function.
                  Input file = "stdev_series.txt"

Run as e.g.     python compare_dF.py std
"""

import numpy as np
import matplotlib.pyplot as plt
from sys import argv, exit

import sim_info

plt.rc('text', usetex=True)
font = {'family' : 'serif',
        'size' : 14}
plt.rc('font', **font)


##################################################
## Compare dF and standard error after N sweeps ##
##################################################
if len(argv) == 1:

    # Input file name
    input_file = "dF_data.txt"

    # Load data
    input_data = np.loadtxt(input_file)
    simID = input_data[:,0]
    Ns = input_data[:,1]
    sweeps_per_s = input_data[:,2]
    dF_mean = input_data[:,3]
    dF_stdev = input_data[:,4]
    dF_stderr = input_data[:,5]

    # Check that all simulations have run for the same Nsweeps
    if np.min(sweeps_per_s) != np.max(sweeps_per_s):
        print "Error: simulations have run for different Nsweeps"
        exit(1)


    # ---------------------- #
    #  Average over repeats  #
    # ---------------------- #
    unique_simID = np.array(list(set(simID)), dtype=int)
    simID = np.array(simID, dtype=int) # convert to int for usid == sid expression
    
    unique_Ns = []
    rep_av_dF_mean = []
    #rep_av_dF_stdev = []
    rep_av_dF_stderr = []
    N_repeats_list = []

    # Iterate over unique simulation ID's
    for usid in unique_simID:

        # Find indices corresponding to repeats to be averaged over
        index_list = [i for i, sid in enumerate(simID) if usid == sid]
        i0 = index_list[0]

        # Keep track of the number of sims we're averaging over
        N_repeats = len(index_list)
        N_repeats_list.append(N_repeats)

        print "Averaging over %d simulations for simID: %d (%s)" \
                %(len(index_list), usid, sim_info.sim_labels[usid])

        # Assume repeats have same Ns - pretty safe to assume
        unique_Ns.append(Ns[i0])

        # Pull out the relevant values
        dF_list = []
        stderr_list = []
        for i in index_list:
            dF_list.append(dF_mean[i])
            stderr_list.append(dF_stdev[i])

        # Take average dF over repeats
        dF_arr = np.array(dF_list)
        rep_av_dF_mean.append(np.mean(dF_arr))

        # Propagate error on dF
        stderr_arr = np.array(stderr_list)
        err_on_sum = np.sqrt(np.sum(stderr_arr**2)) # Add individual errors in quadrature
        rep_av_dF_stderr.append( err_on_sum / N_repeats )


    # Rename things for convenience and convert to arrays of ints
    Ns = np.array(unique_Ns, dtype=int)
    simID = np.array(unique_simID, dtype=int)
    Nsim = len(simID)

    # --------------------------------- #
    #  Plot mean, stderr after Nsweeps  #
    # --------------------------------- #
    fig, ax = plt.subplots()
    ax.tick_params(direction='in', top=True, right=True)
    ax.set_xlabel(sim_info.axis_label)
    ax.set_ylabel("dF")
    ax.set_title("Comparison of dF simulations")

    # Plot mean and standard error
    fake_xticks = np.arange(Nsim)
    ax.errorbar(fake_xticks, rep_av_dF_mean, yerr=rep_av_dF_stderr, fmt='ko')

    # Replace x axis with simID string
    ax.set_xticks(fake_xticks)
    ax.set_xticklabels(sim_info.sim_labels)

    # --------------- #
    #  Save the data  #
    # --------------- #
    data_to_save = np.zeros( (Nsim, 4) )
    data_to_save[:,0] = simID
    data_to_save[:,1] = np.array(N_repeats_list)
    data_to_save[:,2] = np.array(rep_av_dF_mean)
    data_to_save[:,3] = np.array(rep_av_dF_stderr)
    np.savetxt("averaged_dF_data.txt", data_to_save)



############################################
## Compare standard deviation time series ##
############################################
elif argv[1] in ('std', 'psi'):

    # Input file name
    input_file = "stdev_series.txt"
    
    # Load data
    input_data = np.loadtxt(input_file)
    
    # Look for lines with Ns = -1 in second col
    # These separate data from different simulations
    new_sim_rows = np.where( input_data[:,1] == -1 )[0]
    Nsim = len(new_sim_rows)

    # Initialise lists
    simID = []
    Ns = []
    dF_stdev = []
    sweeps_per_s = []
   
    # Separate data from different simulations
    rlo = 0
    for i in range(Nsim):
        rhi = int(new_sim_rows[i])
        
        simID.append(input_data[rlo,0])
        Ns.append(input_data[rlo,1])
        sweeps_per_s.append(input_data[rlo+1:rhi,0])
        dF_stdev.append(input_data[rlo+1:rhi,1])

        rlo = rhi + 1
  
    unique_Ns = []
    N_repeats_list = []
    unique_simID = np.sort(np.array(list(set(simID)), dtype=int)) # low->high simID
    simID = np.array(simID, dtype=int) # convert to int for usid == sid expression


    ########################################
    ## Time series of standard deviations ##
    ########################################
    if argv[1] == 'std':

        unique_sweeps_per_s = []
        rep_av_dF_stdev = []
        rep_stderr_dF_stdev = []

        # ----------------------------- #
        #  Iterate over unique simID's  #
        # ----------------------------- #
        for usid in unique_simID:

            # Find indices corresponding to repeats to be averaged over
            index_list = [i for i, sid in enumerate(simID) if usid == sid]
            i0 = index_list[0]

            # Keep track of the number of sims we're averaging over
            N_repeats = len(index_list)
            N_repeats_list.append(N_repeats)
            print "Averaging over %d simulations for simID: %d (%s)" \
                    %(N_repeats, usid, sim_info.sim_labels[usid])

            # Assume repeats have same Ns - pretty safe to assume
            unique_Ns.append(Ns[i0])

            # Skip the averaging if only one sim
            if N_repeats == 1:
                unique_sweeps_per_s.append(sweeps_per_s[i0])
                rep_av_dF_stdev.append( dF_stdev[i0] )
                rep_stderr_dF_stdev.append( np.zeros(len(dF_stdev[i0])) )
                continue

            # Sweeps array taken from simulation with the most sweeps
            max_sweeps = 0
            i_max_sweeps = 0
            for i in index_list:
                if sweeps_per_s[i][-1] > max_sweeps:
                    i_max_sweeps = i

            # For now, require repeats to have been sampled at the same frequency of sweeps
            unique_sweeps_per_s.append( sweeps_per_s[i_max_sweeps])
       
            # Create wierd array so we can take averages over data of different lengths
            max_len = len(sweeps_per_s[i_max_sweeps])
            data_to_average = np.ma.empty( (max_len, N_repeats) ) # (rows=sweeps, cols=sims)
            data_to_average.mask = True

            # Fill in array with stdev values
            for j in range(len(index_list)):
                i = index_list[j]
                this_data = dF_stdev[i]
                data_to_average[:this_data.shape[0],j] = this_data

            # Average over repeats for each value of sweeps
            data_averaged = np.array( data_to_average.mean(axis=1) )
            rep_av_dF_stdev.append(data_averaged)

            # Append error on the mean to list
            data_stderr = np.array( data_to_average.std(axis=1) ) / np.sqrt(N_repeats)
            rep_stderr_dF_stdev.append( data_stderr )
        
        # End loop of unique simID's
        
        # Rename things for convenience and convert to arrays of ints
        Ns = np.array(unique_Ns, dtype=int)
        simID = np.array(unique_simID, dtype=int)
        sweeps_per_s = unique_sweeps_per_s
        Nsim = len(simID) # now this is number of sims after averaging


        # ---------------------------------------- #
        #  Plot time series of standard deviation  #
        # ---------------------------------------- #
        # Create plot
        fig, ax = plt.subplots()
        ax.tick_params(direction='in', top=True, right=True)
        ax.set_xlabel("Sweeps")
        ax.set_ylabel("Standard deviation on $dF$")
        ax.set_title("Time series of standard deviation")

        i = 0 # int for indexing lists
        for sid in simID: # sorted list of ints, but may have gaps, so not interchangeable with i
            
            # Simulation label and N repeats in legend
            this_label = sim_info.sim_labels[sid] + " (" + str(N_repeats_list[i]) + " repeats)"

            ax.errorbar(sweeps_per_s[i], rep_av_dF_stdev[i], yerr=rep_stderr_dF_stdev[i], \
                        fmt='-', label=this_label)
            i += 1

        ax.legend()


    
    #######################################
    ## Compute and plot speedup function ##
    #######################################
    else:

        # Maybe we calculate speed relative to Np =/= 1 processors
        min_Ns = np.min(Ns)
        print "Computing speedup function defined as:  psi(Np) = X(%d)/X(Np),  (X: sweeps)" %min_Ns

        # Find the smallest std dev which all simulations have converged to 
        convergence = []
        for sim in range(Nsim):

            # Take mean of the last 5 std devs as the level of convergence
            convergence.append( np.mean(dF_stdev[sim][-5:]) )
        stdev_to_compare = np.max(convergence)

        print "Comparing number of sweeps taken to achieve a standard deviation on dF of %f" %stdev_to_compare

        # Find the number of sweeps each sim has taken to achieve this standard deviation
        Nsweeps_converged = []
        for sim in range(Nsim):

            # Work backwards to hopefully avoid flukey early convergence followed by divergence
            for i in range(len(dF_stdev[sim]) - 5):
                this_mean = np.mean(dF_stdev[sim][-i-5:-i])
                if this_mean > stdev_to_compare:
                    Nsweeps_converged.append( sweeps_per_s[sim][-i+1] )
                    break

        # Average over simulations with the same simID
        rep_av_Nsweeps_converged = []
        rep_stderr_Nsweeps_converged = []

        # ----------------------------- #
        #  Iterate over unique simID's  #
        # ----------------------------- #
        for usid in unique_simID:

            # Find indices corresponding to repeats to be averaged over
            index_list = [i for i, sid in enumerate(simID) if usid == sid]
            i0 = index_list[0] 
            
            # Keep track of the number of sims we're averaging over
            N_repeats = len(index_list)
            N_repeats_list.append(N_repeats)
            
            print "Averaging over %d simulations for simID: %d (%s)" \
                    %(len(index_list), usid, sim_info.sim_labels[usid])

            # Assume repeats have same Ns - pretty safe to assume
            unique_Ns.append(Ns[i0])
            
            # Pull out values for sims with this simID
            data_to_average = []
            for i in index_list:
                data_to_average.append(Nsweeps_converged[i])

            # Take mean and standard error
            data_to_average = np.array(data_to_average)
            rep_av_Nsweeps_converged.append(np.mean(data_to_average))
            rep_stderr_Nsweeps_converged.append(np.std(data_to_average) / np.sqrt(len(index_list)))

        # End loop over unique simID's

        # Rename things for convenience and convert to arrays of ints
        Ns = np.array(unique_Ns, dtype=int)
        simID = np.array(unique_simID, dtype=int)
        Nsim = len(simID) # now this is number of sims after averaging

        # Compute speedup function
        rep_av_Nsweeps_converged = np.array(rep_av_Nsweeps_converged)
        sweeps_serial = rep_av_Nsweeps_converged[ Ns==min_Ns ]
        psi = np.ones(Nsim)*sweeps_serial / rep_av_Nsweeps_converged
        
        # Compute uncertainty on speedup functioin by propagating the uncertainty
        # on the mean sweeps using the functional approach
        psi_plus_err = np.ones(Nsim)*sweeps_serial / \
                (rep_av_Nsweeps_converged+rep_stderr_Nsweeps_converged)
        psi_err = np.abs(psi - psi_plus_err)

        # Compute fit parameters
        coeffs = np.polyfit(Ns, psi, 1)
        fit = Ns*coeffs[0] + coeffs[1]


        # ----------------------- #
        #  Plot speedup function  #
        # ----------------------- #
        # Create plot
        fig, ax = plt.subplots()
        ax.tick_params(direction='in', top=True, right=True)
        ax.set_xlabel(r"$\sqrt{Ns}$")
        ax.set_ylabel(r"$\psi$")
        ax.set_title("Speedup function")

        # Add text to show the standard deviation
        rootNs = np.sqrt(Ns)
        coords = (rootNs[0], np.max(psi+0.5*psi_err))
        ax.text(coords[0], coords[1], \
                "Comparing sweeps to \nreach $\sigma=$ %1.1e" %stdev_to_compare)

        # Plot data
        ax.errorbar(rootNs, psi, yerr=psi_err, fmt='ko')
        ax.plot(rootNs, fit, 'r--')
    


plt.show()

